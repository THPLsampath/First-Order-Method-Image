{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# YOLO v2\n",
        "![alt text](https://pjreddie.com/media/image/model2.png)\n",
        "\n",
        "(The image above is taken from the [official YOLO v2 homepage](https://pjreddie.com/darknet/yolov2/))\n",
        "\n",
        "This example interactively demonstrates [YOLO v2](https://openaccess.thecvf.com/content_cvpr_2017/papers/Redmon_YOLO9000_Better_Faster_CVPR_2017_paper.pdf), a model for object detection.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Preparation\n",
        "Let's start by installing nnabla and accessing [nnabla-examples repository](https://github.com/sony/nnabla-examples). If you're running on Colab, make sure that your Runtime setting is set as GPU, which can be set up from the top menu (Runtime â†’ change runtime type), and make sure to click **Connect** on the top right-hand side of the screen before you start."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "!pip install nnabla-ext-cuda100\n",
        "!git clone https://github.com/sony/nnabla-examples.git\n",
        "%run nnabla-examples/interactive-demos/colab_utils.py\n",
        "%cd nnabla-examples/object-detection/yolov2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let's also download pre-trained weight parameters and auxiliary file. We will also convert the weight parameters to .h5 format to make it compatible with NNabla. This may take a few minutes."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "!wget https://pjreddie.com/media/files/yolov2.weights\n",
        "!wget https://raw.githubusercontent.com/pjreddie/darknet/master/data/coco.names\n",
        "!python convert_yolov2_weights_to_nnabla.py --input yolov2.weights"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Upload Image\n",
        "Run the following cell to upload your own image.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "from google.colab import files\n",
        "\n",
        "img = files.upload()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let's rename the image for convenience.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import os\n",
        "ext = os.path.splitext(list(img.keys())[-1])[-1]\n",
        "os.rename(list(img.keys())[-1], \"input_image{}\".format(ext)) \n",
        "input_img = \"input_image\" + ext"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Object Detection\n",
        "Now let's run YOLO v2 to your image and see how it performs object detection!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "!python yolov2_detection.py $input_img\n",
        "from IPython.display import Image,display\n",
        "print('Input:')\n",
        "display(Image(input_img))\n",
        "output_img = \"detect.input_image\"+ext\n",
        "print('Output:')\n",
        "display(Image(output_img))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# For Smartphone Users\n",
        "If you're using a smartphone with a camera, you can take a photo and use that image for this demo.\n",
        "Just execute the following cell and tap `Capture` button. \n",
        "\n",
        "If your device has multiple cameras (such as front and back) you need to select which one to use by tapping the corresponding button (which should appear near the 'Capture' button).\n",
        "\n",
        "**Note this is an experimental support and may not work in some devices.**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "try:\n",
        "    filename = take_photo(cam_width=608, cam_height=608)\n",
        "    print('Saved to {}'.format(filename))\n",
        "    # Show the image which was just taken.\n",
        "    display(Image(filename))\n",
        "except Exception as err:\n",
        "    # Errors will be thrown if the user does not have a webcam or if they do not\n",
        "    # grant the page permission to access it.\n",
        "    print(str(err))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "If the photo is OK, let's try object detection. If you want to use another photo, just re-run the previous cell again.\n",
        "\n",
        "The following cell will execute object detection on your photo."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "!python yolov2_detection.py photo.png --output photo_output.png\n",
        "from IPython.display import Image,display\n",
        "print('Output:')\n",
        "display(Image('photo_output.png'))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "accelerator": "GPU",
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
