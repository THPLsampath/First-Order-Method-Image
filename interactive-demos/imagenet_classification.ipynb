{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Image Classification\n",
        "\n",
        "This example demonstrates image classifications with different types of state-of-the-art neural networks, such as [ResNet](https://www.cv-foundation.org/openaccess/content_cvpr_2016/papers/He_Deep_Residual_Learning_CVPR_2016_paper.pdf), [ResNeXt](https://openaccess.thecvf.com/content_cvpr_2017/papers/Xie_Aggregated_Residual_Transformations_CVPR_2017_paper.pdf), and [SENet](https://openaccess.thecvf.com/content_cvpr_2018/papers/Hu_Squeeze-and-Excitation_Networks_CVPR_2018_paper.pdf)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Preparation\n",
        "Let's start by installing nnabla and accessing [nnabla-examples repository](https://github.com/sony/nnabla-examples). If you're running on Colab, make sure that your Runtime setting is set as GPU, which can be set up from the top menu (Runtime â†’ change runtime type), and make sure to click **Connect** on the top right-hand side of the screen before you start."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "!pip install nnabla-ext-cuda100\n",
        "!git clone https://github.com/sony/nnabla-examples.git\n",
        "%run nnabla-examples/interactive-demos/colab_utils.py\n",
        "%cd nnabla-examples/imagenet-classification"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Next, select the neural network type from the dropdown menu and execute the cell."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "network_name = \"ResNet50\" #@param [\"ResNet18\", \"ResNet34\", \"ResNet50\", \"ResNet101\", \"ResNet152\", \"ResNeXt50\", \"SE-ResNet50\", \"SE-ResNeXt50\"]\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We will now download the pre-trained weight parameters for the selected neural network."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "if network_name == \"ResNet18\":\n",
        "    url = \"https://nnabla.org/pretrained-models/nnabla-examples/ilsvrc2012/rn18-nhwc_mixup250.h5\"\n",
        "elif network_name == \"ResNet34\":\n",
        "    url = \"https://nnabla.org/pretrained-models/nnabla-examples/ilsvrc2012/rn34-nhwc_mixup250.h5\"\n",
        "elif network_name == \"ResNet50\":\n",
        "    url = \"https://nnabla.org/pretrained-models/nnabla-examples/ilsvrc2012/rn50-nhwc_mixup250.h5\"\n",
        "elif network_name == \"ResNet101\":\n",
        "    url = \"https://nnabla.org/pretrained-models/nnabla-examples/ilsvrc2012/rn101-nhwc.h5\"\n",
        "elif network_name == \"ResNet152\":\n",
        "    url = \"https://nnabla.org/pretrained-models/nnabla-examples/ilsvrc2012/rn152-nhwc_cos90.h5\"\n",
        "elif network_name == \"ResNeXt50\":\n",
        "    url = \"https://nnabla.org/pretrained-models/nnabla-examples/ilsvrc2012/resnext50_nhwc_mixup250.h5\"\n",
        "elif network_name == \"SE-ResNet50\":\n",
        "    url = \"https://nnabla.org/pretrained-models/nnabla-examples/ilsvrc2012/se_resnet50_nhwc_mixup250.h5\"\n",
        "elif network_name == \"SE-ResNeXt50\":\n",
        "    url = \"https://nnabla.org/pretrained-models/nnabla-examples/ilsvrc2012/se_resnext50_nhwc_mixup250.h5\"\n",
        "\n",
        "!wget $url\n",
        "params = url.split('/')[-1]\n",
        "network_name = network_name.lower().replace('-','_')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Upload image\n",
        "Now, upload an image you'd like to classify.\n",
        "Basically, most networks are trained to predict images of single objects, but you may examine different types of images."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "from google.colab import files\n",
        "\n",
        "img = files.upload()\n",
        "\n",
        "#Renaming the file for convenience. You can ignore the lines below.\n",
        "import os\n",
        "ext = os.path.splitext(list(img.keys())[-1])[-1]\n",
        "os.rename(list(img.keys())[-1], \"input_image{}\".format(ext)) \n",
        "input_img = \"input_image\" + ext"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Classification\n",
        "Finally, let's classify your image!\n",
        "\n",
        "The following cell will show the top-5 predictions along with the probability for each prediction.\n",
        "\n",
        "Play around with different types of images and different neural networks!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "from IPython.display import Image,display\n",
        "display(Image(input_img))\n",
        "!python infer.py $input_img $params -a $network_name"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# For Smartphone Users\n",
        "If you're using a smartphone with a camera, you can take a photo and use that image for this demo.\n",
        "Just execute the following cell and tap `Capture` button. \n",
        "\n",
        "If your device has multiple cameras (such as front and back) you need to select which one to use by tapping the corresponding button (which should appear near the 'Capture' button).\n",
        "\n",
        "**Note this is an experimental support and may not work in some devices.**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "try:\n",
        "    filename = take_photo()#cam_width=256, cam_height=256)\n",
        "    print('Saved to {}'.format(filename))\n",
        "    # Show the image which was just taken.\n",
        "    display(Image(filename))\n",
        "except Exception as err:\n",
        "    # Errors will be thrown if the user does not have a webcam or if they do not\n",
        "    # grant the page permission to access it.\n",
        "    print(str(err))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "If the photo is OK, let's try classification. If you want to use another photo, just re-run the previous cell again.\n",
        "\n",
        "The following cell will execute classification on your photo."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "!python infer.py \"photo.png\" $params -a $network_name"
      ],
      "execution_count": null,
      "outputs": []
    }
  ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "accelerator": "GPU",
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
