{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "871526ab",
   "metadata": {},
   "source": [
    "# File Format Converter\n",
    "File format converter is converter module provided by NNabla. It realize Neural Network Libraries (or Console) workflow with ONNX file format, and also NNabla C Runtime. More see [file format converter document](https://nnabla.readthedocs.io/en/latest/python/file_format_converter/file_format_converter.html).\n",
    "\n",
    "# Functions supported file format converter\n",
    "\n",
    "* Convert NNP variations to valid NNP\n",
    "\n",
    "* Convert ONNX to NNP\n",
    "\n",
    "* Convert NNP to ONNX\n",
    "\n",
    "* Convert NNP to NNB(Binary format for NNabla C Runtime)\n",
    "\n",
    "* Convert NNP to Tensorflow saved_model\n",
    "\n",
    "* Convert Tensorflow checkpoint, frozen graph or saved_model to NNP\n",
    "\n",
    "* Convert NNP to Tensorflow Lite\n",
    "\n",
    "* Convert NNP to INT8 quantized Tensorflow Lite\n",
    "\n",
    "* Convert Tensorflow Lite to NNP\n",
    "\n",
    "* Experimental: Convert NNP to C Source code for NNabla C Runtime\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29d9d2b2",
   "metadata": {},
   "source": [
    "# How to convert NNP model to ONNX model\n",
    "\n",
    "In this section, this example shows how to convert Nnabla's NNP model to ONNX model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b897ac4",
   "metadata": {},
   "source": [
    "####  Install nnabla, nnabla_converter, onnx, matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad008a30",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install nnabla nnabla_converter matplotlib onnxruntime"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39c8de44",
   "metadata": {},
   "source": [
    "#### Inference by nnabla"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d3094a7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import zlib\n",
    "import struct\n",
    "import numpy as np\n",
    "import nnabla as nn\n",
    "import matplotlib.pyplot as plt\n",
    "from nnabla.utils.nnp_graph import NnpLoader\n",
    "from nnabla.utils.data_source_loader import download\n",
    "from nnabla.logger import logger\n",
    "\n",
    "result_dir = \"./nnabla_data\"\n",
    "os.makedirs(result_dir, exist_ok=True)\n",
    "\n",
    "\n",
    "def load_mnist_test_set():\n",
    "    image_uri = 'http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz'\n",
    "    label_uri = 'http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz'\n",
    "    logger.info('Getting label data from {}.'.format(label_uri))\n",
    "    r = download(label_uri, output_file=f\"{result_dir}/labels.gz\")\n",
    "    data = zlib.decompress(r.read(), zlib.MAX_WBITS | 32)\n",
    "    _, size = struct.unpack('>II', data[0:8])\n",
    "    labels = np.frombuffer(data[8:], np.uint8).reshape(-1, 1)\n",
    "    r.close()\n",
    "    logger.info('Getting label data done.')\n",
    "\n",
    "    logger.info('Getting image data from {}.'.format(image_uri))\n",
    "    r = download(image_uri, output_file=f\"{result_dir}/images.gz\")\n",
    "    data = zlib.decompress(r.read(), zlib.MAX_WBITS | 32)\n",
    "    _, size, height, width = struct.unpack('>IIII', data[0:16])\n",
    "    images = np.frombuffer(data[16:], np.uint8).reshape(\n",
    "        size, 1, height, width)\n",
    "    r.close()\n",
    "    logger.info('Getting image data done.')\n",
    "\n",
    "    return images, labels\n",
    "\n",
    "\n",
    "def load_nnp(nnp_file):\n",
    "    \n",
    "    # download nnp file\n",
    "    url = \"http://nnabla.org/pretrained-models/nnabla-examples/format-converter/mnist.nnp\"\n",
    "    download(url, output_file=nnp_file)\n",
    "    \n",
    "    nnp = NnpLoader(nnp_file)\n",
    "    net = nnp.get_network(nnp.get_network_names()[0], batch_size=1)\n",
    "    input_var = net.inputs[list(net.inputs.keys())[0]]\n",
    "    output_var = net.outputs[list(net.outputs.keys())[0]]\n",
    "    return input_var, output_var\n",
    "\n",
    "\n",
    "# Test with NNabla\n",
    "nnp_file = f\"{result_dir}/ffc_demo.nnp\"\n",
    "test_imgs, test_labels = load_mnist_test_set()\n",
    "x, y = load_nnp(nnp_file)\n",
    "n = 3 # number of images used for demo\n",
    "\n",
    "for img in test_imgs[:n]:\n",
    "    input_data = np.expand_dims(img, 0).astype(np.float32) / 255.0\n",
    "    x.d = input_data\n",
    "    y.forward()\n",
    "    pred = np.argmax(y.d[0])\n",
    "    plt.title('prediction: {}'.format(pred))\n",
    "    plt.imshow(img[0])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "370f7cfd",
   "metadata": {},
   "source": [
    "#### Convert NNabla model to ONNX model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "194d1519",
   "metadata": {},
   "outputs": [],
   "source": [
    "!nnabla_cli convert -b 1 ./nnabla_data/ffc_demo.nnp ./nnabla_data/ffc_demo.onnx"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb106571",
   "metadata": {},
   "source": [
    "#### Inference by ONNX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "635419b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test with ONNX\n",
    "\n",
    "import onnxruntime as ort\n",
    "\n",
    "onnxmodel = f\"{result_dir}/ffc_demo.onnx\"\n",
    "sessionOptions = ort.SessionOptions()\n",
    "sessionOptions.intra_op_num_threads = 1\n",
    "sessionOptions.execution_mode = ort.ExecutionMode.ORT_SEQUENTIAL\n",
    "sess = ort.InferenceSession(onnxmodel, sess_options=sessionOptions)\n",
    "input_name = sess.get_inputs()[0].name\n",
    "output_name = sess.get_outputs()[0].name\n",
    "\n",
    "for img in test_imgs[:n]:\n",
    "    input_data = np.expand_dims(img, 0).astype(np.float32) / 255.0\n",
    "    pred = sess.run([output_name], {input_name: input_data})\n",
    "    pred = np.argmax(pred[0])\n",
    "    plt.title('prediction: {}'.format(pred))\n",
    "    plt.imshow(img[0])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03b4500b",
   "metadata": {},
   "source": [
    "#### Time differences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d63b2eef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare NNabla and ONNX\n",
    "\n",
    "import time\n",
    "\n",
    "t1 = time.time()\n",
    "x.d = input_data\n",
    "for i in range(1000):\n",
    "    y.forward()\n",
    "t2 = time.time()\n",
    "nnabla_time = t2 - t1\n",
    "\n",
    "t1 = time.time()\n",
    "for i in range(1000):\n",
    "    pred = sess.run([output_name], {input_name: input_data})\n",
    "t2 = time.time()\n",
    "onnx_time = t2 - t1\n",
    "\n",
    "print('NNabla takes {:.3f} seconds to inference 1000 times'.format(nnabla_time))\n",
    "print('ONNX takes {:.3f} seconds to inference 1000 times'.format(onnx_time))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
