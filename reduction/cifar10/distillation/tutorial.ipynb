{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Distillation Example\n",
    "\n",
    "In this example, Distillation is used for neural network reduction. \n",
    "The technique, Distillation, is not limited for this purpose; in other words, \n",
    "one can distil knowledges a network learned to other networks, in other usecases, \n",
    "feature learning, network quantization, etc. In Distillation, there are (basically) two networks exist, one is called `Teacher` and \n",
    "the other is called `Student`. Teacher provides knowledge learned, \n",
    "e.g., inference results of the teacher, to Student in the training pipeline. In order to use Distillation, first, one trains Teacher network, then by using that Teacher trained, \n",
    "distills that knowledge to Student.\n",
    "\n",
    "The follows show the workflow when one reduces the size of a network by using `Distillation`.\n",
    "\n",
    "1. Train a teacher network.\n",
    "2. Distil that knowledge to another network, usually called student.\n",
    "\n",
    "`classification.py` corresponds to the first one, and `distillation.py` does the second."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To use this example, train a teacher network as follows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```sh\n",
    "python classification.py -c \"cudnn\" \\\n",
    "    --monitor-path \"monitor.teacher\" \\\n",
    "    --model-save-path \"monitor.teacher\" \\\n",
    "    -d 0\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can get the training results under monitor.teacher, then use the result with the reduction rate of 0.5,"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```sh\n",
    "python distillation.py -c \"cudnn\" \\\n",
    "    --reduction-rate 0.5 \\\n",
    "    --monitor-path \"monitor.student.rrate-05\" \\\n",
    "    --model-save-path \"monitor.student.rrate-05\" \\\n",
    "    --model-load-path \"monitor.teacher/${the best result}.h5\" \\\n",
    "    -d 0\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# References\n",
    "\n",
    "1. Hinton Geoffrey, Vinyals Oriol, and Dean Jeff, \"Distilling the Knowledge in a Neural Network\", arXiv:1503.02531"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
