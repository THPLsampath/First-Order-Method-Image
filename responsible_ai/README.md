# Responsible AI

![](./imgs/responsible_ai.png)

## Overview

These are examples of responsible AI that consists of eXplainable AI and fairness of machine learning. 


In order to utilize AI technology to enrich human's life style and contribute to the development of society, we will pursue fairness,  transparency, and accountability while actively engaging in dialogue with stakeholders. We will continue to contribute responsible AI in order to maintain the trustworthy of our products and services.

---

# 1. Visualization
## Grad-CAM [code](./gradcam/)
> **Grad-CAM: Visual Explanations from Deep Networks via Gradient-based Localization**
> Ramprasaath R. Selvaraju, Michael Cogswell, Abhishek Das, Ramakrishna Vedantam, Devi Parikh, Dhruv Batra.
> *arXiv technical report ([arXiv 1610.02391](https://arxiv.org/abs/1610.02391))* 

<p align="center">
<img src="./gradcam/images/sample.png" width="500px">  
</p>


## SHAP (image data) [code](./shap/)
> **A Unified Approach to Interpreting Model Predictions**
> Scott Lundberg, Su-In Lee.
> *arXiv technical report ([arXiv 1705.07874](https://arxiv.org/abs/1705.07874))* 

<p align="center">
<img src="./shap/images/sample.png" width="500px">  
</p>

## Kernel SHAP (tabular data) [code](./kernel_shap/)
> **A Unified Approach to Interpreting Model Predictions**
> Scott Lundberg, Su-In Lee.
> *arXiv technical report ([arXiv 1705.07874](https://arxiv.org/abs/1705.07874))* 

<p align="center">
<img src="./kernel_shap/images/sample.png" width="500px">  
</p>

</br>

# 2. Influence
## Data cleansing with with Storage-efficient Approximation of Influence Functions [code](./data_cleansing/)

> **Data Cleansing for Deep Neural Networks with Storage-efficient Approximation of Influence Functions**
> Kenji Suzuki, Yoshiyuki Kobayashi, Takuya Narihira.
> *arXiv technical report ([arXiv 2103.11807]( https://arxiv.org/abs/2103.11807))*            

![](./data_cleansing/imgs/datacleansing.png)


## Understanding Black-box Predictions via Influence Functions [code](./data_cleansing/)

> **Understanding Black-box Predictions via Influence Functions**
> Pang Wei Koh, Percy Liang.
> *arXiv technical report ([arXiv 1703.04730]( https://arxiv.org/abs/1703.04730))*            


## TracIn [code](./tracin/)
> **Estimating Training Data Influence by Tracing Gradient Descent**
> Garima Pruthi, Frederick Liu, Mukund Sundararajan, Satyen Kale.
> *arXiv technical report ([arXiv 2002.08484](https://arxiv.org/abs/2002.08484))* 

## Representer Point [code](./representer_point/)
> **Representer Point Selection for Explaining Deep Neural Networks**
> Chih-Kuan Yeh, Joon Sik Kim, Ian E.H. Yen, Pradeep Ravikumar.
> *arXiv technical report ([arXiv 1811.09720](https://arxiv.org/abs/1811.09720))* 

<br>

# 3. Fairness
## Fairness of Machine Learning [code](./gender_bias_mitigation/)
> **Data preprocessing techniques for classification without discrimination**
> Kamiran, Faisal and Calders, Toon. 
> [Knowledge and Information Systems, 33(1):1â€“33, 2012](https://link.springer.com/content/pdf/10.1007/s10115-011-0463-8.pdf)* 

<p align="center">
<img src="./gender_bias_mitigation/images/xai-bias-mitigation-workflow.png">
</p>

## Facial evaluation for skin color [code](./face_evaluation/)
> **Diversity in Faces**
> Michele Merler, Nalini Ratha, Rogerio S. Feris, John R. Smith.
> *arXiv technical report ([arxiv 1901.10436](https://arxiv.org/abs/1901.10436))* 

<p align="center">
<img src="./face_evaluation/skin_color.png">
</p>

