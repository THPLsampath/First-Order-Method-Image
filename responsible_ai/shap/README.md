# SHAP
SHAP (SHapley Additive exPlanation) is an approach to explain the output of any machine learning model using game theory. It links optimal credit allocation with local explanations using the classic Shapley values from game theory and their related extensions. This example is an implementation of [this paper](https://arxiv.org/abs/1705.07874) with Neural Network Libraries. 


<p align="center">
<img src='images/sample.png'>
</p>
<p align="center">
Figure: Visual explanations on the image samples.
</p>


# Interactive demo

**eXplainable AI**
|Name| Notebook           | Task  | Example                       |
|:---------------------------------:|:-------------:|:-----:|:------------:|
 [SHAP](https://arxiv.org/abs/1705.07874) | [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/sony/nnabla-examples/blob/master/interactive-demos/shap.ipynb) | SHAP |<a href="url"><img src="https://github.com/sony/nnabla-examples/raw/master/responsible_ai/shap/images/sample.png" align="center" height="90" ></a>|
 
# Citation
This is based on [A Unified Approach to Interpreting Model Predictions](https://arxiv.org/abs/1705.07874).

